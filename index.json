[{"content":"","date":"10 November 2023","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"10 November 2023","permalink":"/tags/computer-vision/","section":"Tags","summary":"","title":"computer-vision"},{"content":"","date":"10 November 2023","permalink":"/tags/datascience/","section":"Tags","summary":"","title":"datascience"},{"content":"","date":"10 November 2023","permalink":"/tags/dataset/","section":"Tags","summary":"","title":"dataset"},{"content":"","date":"10 November 2023","permalink":"/tags/deep-learning/","section":"Tags","summary":"","title":"deep learning"},{"content":"","date":"10 November 2023","permalink":"/tags/label-studio/","section":"Tags","summary":"","title":"label-studio"},{"content":"Note: This guide was written using label-studio version 1.8.2.post1.\nWith the modules included in pytorch, opencv or ultralytics, training computer vision models is easier than ever, the main constraint being the availability of labeled data. While there are many \u0026ldquo;smart\u0026rdquo; labeling solutions, most of them are either expensive or not open source. Label-studio is unique in that it free to use, open source and even can be made \u0026ldquo;smart\u0026rdquo; by adding your own pre-labeling network for automatic labeling.\nBut setting up label-studio locally to correct pre-annotated images of my YOLO dataset that I passed through a Faster R-CNN model trained on synthetic data took me about two days. So I decided to write this in case I forget how I did it. And maybe it helps someone else before they waste two days of their life.\n1. Convert the dataset to label studio format # First of all, you need a dataset in the YOLO format, which is structured like this:\ndataset ├── classes.txt ├── images │ ├── image1.png │ ├── image2.png │ └── ... └── labels ├── image1.txt ├── image2.txt └── ... Label studio cannot directly import a YOLO dataset that is labeled. It could import the images only, but for the labels to be loaded as well, we need to convert them to the label-studio json format.\nThis can be achieved by the label-studio-converter tool, which comes with label studio.\nThe converter needs 4 parameters:\n--input: The path to the dataset, i.e. in our case that would be /home/user/data/dataset\n--output: The path to the output file, i.e. /home/user/data/dataset/output.json. To make life easier, just put it into the dataset root directory.\n--image-root-url: Now this is the tricky one: The root URL is now a relative path. Don\u0026rsquo;t ask me why, but it needs to be relative to the parent of the root URL exported as our environment variable (as you will see later). And to make life even harder, it needs to be prefixed with /data/local-files/?d=. So in our case, the root URL would be /data/local-files/?d=dataset/images. Label studio will serve the images from the root URL and the images are located in the images folder of the dataset.\n--image-ext: The file extension of the images. In our case, that would be .png.\nAnd to assemble the full command:\nlabel-studio-converter import yolo -i /home/user/data/dataset -o /home/user/data/dataset/output.json --image-root-url \u0026#34;/data/local-files/?d=dataset/images\u0026#34; --image-ext .png This will write two files into the dataset directory: output.json and output.label_config.xml. The latter one contains the label format that we need to import the dataset into label studio.\n2. Export environment variables # To label local images, label-studio needs to be launched with two environment variables set. The first one enables local file serving and the second one sets the document root.\nThe document root must be an absolute path and the direct parent of the dataset directory. Example: If the root URL is /home/user/data then the dataset, itself containing an image and label folder, must reside in e.g. /home/user/data/dataset.\nexport LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true export LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/home/user/data To make this easier, I put this into a small bash script that exports the variables and launches label studio:\n#!/bin/bash export LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true export LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/home/user/data label-studio Just do a chmod +x on the script and you can start label studio with ./label-studio.sh.\n3. Create a new project in label studio # Open label-studio and create a new project.\nGive your project some name. Paste the content of the output.label_config.xml file into the label config field. Go to the settings and add a Cloud Storage, choosing Local Storage as the type. Set the storage root URL as an absolute path to the root of your dataset, i.e. /home/user/data/dataset. Now, import the output.json file into the project. You should now have the labels and images loaded into label studio.\n4. Label the images # Your project should now be ready to correct the labels. You can now start labeling the images. Once you are done, you can export the labels using the export button back into the YOLO format. This will produce a zip file containing the images and the labels. Unzip it and you are back where you started just with hopefully better labels.\nI hope this helps someone. If you have any questions, feel free to contact me.\n","date":"10 November 2023","permalink":"/posts/label_studio_yolo/","section":"Posts","summary":"Note: This guide was written using label-studio version 1.8.2.post1.\nWith the modules included in pytorch, opencv or ultralytics, training computer vision models is easier than ever, the main constraint being the availability of labeled data.","title":"Labeling pre-annotated images of a YOLO dataset with label-studio"},{"content":"","date":"10 November 2023","permalink":"/categories/post/","section":"Categories","summary":"","title":"Post"},{"content":"","date":"10 November 2023","permalink":"/tags/supervised-learning/","section":"Tags","summary":"","title":"supervised-learning"},{"content":"","date":"10 November 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":" Hi there, I\u0026rsquo;m Patrick! I am a Masters student in the Neuroethology group at the University of Tuebingen. I am interested in the quantitative study of animal behavior and data science. I am also a Linux and open source software enthusiast. Click here to learn more.\n","date":"10 November 2023","permalink":"/","section":"Welcome","summary":"Hi there, I\u0026rsquo;m Patrick! I am a Masters student in the Neuroethology group at the University of Tuebingen. I am interested in the quantitative study of animal behavior and data science.","title":"Welcome"},{"content":"","date":"10 November 2023","permalink":"/tags/yolo/","section":"Tags","summary":"","title":"yolo"},{"content":"","date":"7 November 2023","permalink":"/tags/2023/","section":"Tags","summary":"","title":"2023"},{"content":"Recently, I had the privilege of joining Jan Benda on a remarkable research expedition to delve into the captivating realm of electric fish in the Amazonian Rainforest.\nOver the course of nine days at a remote field station, I was immersed in the challenges and wonders of this unique ecosystem, all in pursuit of unraveling the mysteries of these enigmatic aquatic creatures.\nA Pictorial Journey # Let\u0026rsquo;s start with some visuals to set the scene:\nWhy Electric Fish? # In the vast expanse of the Neotropics, electric fish are ubiquitous. While most people have heard of the electric eel, there are numerous lesser-known species that are small, nocturnal, and rarely observed without specialized equipment. These \u0026lsquo;weakly\u0026rsquo; electric fish utilize their electric organs for communication, navigation, and hunting in the Amazonian Rainforest waters. While they serve as a popular model in Neurophysiology, their ecological roles, natural behaviors, and communication methods remain largely enigmatic. This is where our journey begins.\nGymnorhamphichthys, a pulse-type weakly electric fish that inhabits the sand banks of Amazonian rivers. The Research Objective # Wave-type electric fish, comprising many species, are unique in that they constantly emit an electric field. We can measure this field using electrodes and amplifiers. Moreover, the field of each fish oscillates at a unique frequency, allowing us to distinguish them. Our aim is to take this a step further: employing electrode grids to measure the electric field on a plane and reconstruct the movements, communication, and even the mating behaviors of multiple individuals in their natural habitat. While similar work has been done before, we aim to (1) enhance the resolution from the previous 64 to 256 electrodes and (2) make the system portable, modular, and robust. During this field trip, we tested the first prototype of this system.\nThe Expedition to the Field Station # Reaching our field station was no easy feat. We embarked on a journey that took us from Frankfurt to Lisbon and then to Belem, a city in northern Brazil. From Belem, we hopped on a small plane to Macapa, the capital of the state of Amapa. From there, we were graciously driven to Porto Grande by Christoph Jaster, head of the local park administration, where we met our boatsman, Junior, who would transport us to the field station. After two hours in the car and another two hours on the river, we arrived at the southernmost tip of the FLONA do Amapa, a national park nestled within the Amazonian Rainforest.\nThe field station, a small house covered by the dense canopy of the Amazonian Rainforest. The field station itself, perched at the confluence of the Rio Falsino and the Rio Araguari, was a humble abode with a small kitchen, a bathroom, and space for hammocks. In the evenings, a generator powered the lights, and we even had satellite internet. However, most of the time, we were serenaded by the sounds of the rainforest, the chirping of birds, and the distant howling of monkeys.\nA Day in the Life at the Field Station # Our days began with the early rising sun at around 6 AM. After a quick breakfast, the mornings were devoted to setting up, fixing, or debugging our equipment. In the afternoons, Junior would ferry us to the river for fieldwork, where we tested our recording hardware.\nJan and me taking a first look at new data on our favorite riverbank. Navigating the river\u0026rsquo;s shallows and rapids was exhilarating, especially since our visit coincided with the dry season, causing the water levels to drop noticeably. Despite the challenges, Junior skillfully guided our boat, and we never found ourselves stranded or pushing the boat through shallow waters. Maneuvering through the river\u0026rsquo;s rapids proved to be an enjoyable part of our daily routine.\nOn the lookout for big rocks beneath the surface. The sweltering midday heat often left us lethargic, prompting us to seek respite in our hammocks for a brief siesta or to cool off in the 32°C river waters. These moments also offered the opportunity to wash and dry our clothes in the sun within a few hours.\nMost evenings, we returned from the river with new challenges to tackle, leading us to spend the nights fixing and debugging our equipment. Telma, our cook, prepared delectable meals for us, providing much-needed relief from cooking duties. After dinner, our evenings were dedicated to data analysis and equipment maintenance. Falling asleep in our sweaty hammocks, enveloped by the sounds of the rainforest, was a welcome reprieve after a long day\u0026rsquo;s work.\nEquipment and Data Collection # Our expedition was equipped with two main categories of hardware:\nFish Finders # At its simplest, a fish finder can be an audio amplifier. However, instead of plugging in a guitar or microphone, we connected our electrodes. This allowed us to audibly detect the electric organ discharges of the fish. While mere audio signals sufficed for locating the fish, Jan is in the process of developing a Smart Fish Finder with a screen capable of plotting fish waveforms. This advancement will enable us to discern the genus of the fish without visual confirmation.\nJan using his fish finder to record a Gymnorhamphichthys in the sand. Recording Hardware # Once we identified promising recording locations, we deployed our logging devices. Our goal is to create a platform of affordable, waterproof loggers constructed from readily available components. The most exciting aspect? These loggers are modular and adaptable for various recording purposes:\nLogger Configuration # Each logger consists of a microcontroller, a battery, an SD card, and currently, a temperature sensor. It can receive input from up to 16 electrodes, with recording duration limited only by the SD card\u0026rsquo;s capacity and battery life. In theory, they could record data for months, and deploying a network of loggers over a large area could capture migratory patterns of fish. This is the configuratino we tested the most on during our field trip.\nGrid Configuration # Our plan is to employ these same loggers, with the addition of a cable for power, arranged side by side to form an electrode grid. With 16 electrodes, the placement of 16 loggers would result in a 256-electrode grid. This setup would enable us to record the electric field on a plane, facilitating the reconstruction of interactions and communication among multiple individuals. However, after five days of rigorous testing and debugging, we discovered that the current circuit boards introduced interference when devices were placed closely together. Thus, we will need to redesign and retest the circuit boards in the future.\nWildlife and Biodiversity # In addition to our electric fish research, our time in the rainforest afforded us the opportunity to observe a myriad of wildlife. We encountered a variety of avian species, including toucans, parrots, macaws, hummingbirds, and more. Our journey also brought us in contact with numerous insects, captivating moths and butterflies, reptiles, and amphibians.\nMost of the fish we encountered were small catfish, as the electric fish we sought tend to hide in crevices during the day. Nevertheless, we did have a few remarkable encounters, including Eigenmannia at night and an Archolaemus, which I managed to capture on video with my phone as it nestled between two rocks. This endeavor resulted in an amusing photo of me attempting to capture a good shot of the fish.\nObtaining a video was a source of great joy, given the elusive nature of these fish. Communicating about them using only data points on a screen can be challenging, so having a video was invaluable.\nWe also encountered a specimen of Gymnorhamphichthys, a pulse-type weakly electric fish that buries itself in the sand on riverbanks. Without our electrodes, locating them would have been exceedingly difficult, but with their help, we pinpointed two of them and even recorded a video of one. The background noise you hear is the electric organ discharge, which our amplifiers convert into sound.\nHowever, one electric fish appeared to shadow us wherever we ventured: Electrophorus, the electric eel. On our first day in the field, as we explored a small tributary of the Rio Falsino, we encountered four eels, each about 1.5 meters in length, serenely lounging in shallow water.\nIn the ensuing days, similar scenes greeted us each time we approached areas where smaller streams met the main channel. We also detected them (not visually, but via our fish finders) while working in the middle of the river. Picture standing chest-deep in the middle of a river, immersed in your work, and suddenly hearing the distinct \u0026rsquo;toc, toc, toc\u0026rsquo; of an approaching electric eel. When we heard them on the amplifiers, we knew they were just meters away, prompting us to swiftly exit the water and wait for them to pass. We also learned that they frequently traversed the swimming area at the station, as we had recorded them there before. Over time, we stopped carrying the fish finders when we wanted to relax and cool off, leaving the door open for future underwater encounters.\nI must confess that I had underestimated these creatures. I once naively assumed them to be \u0026lsquo;simple,\u0026rsquo; solitary hunters that relied on their electric organ to stun prey. However, as we were fortunate to observe, they are highly social animals, with documented instances of group hunting. I am eager to see what we can uncover about them in the future.\nAn electric eel passing by our recording electrodes on a tributary of the Rio Falsino. Challenges and Lessons Learned # Our expedition was not without its share of challenges, some expected and others not. Yet, we garnered valuable lessons and insights from them, fueling our enthusiasm to return to the field and test our new equipment.\nThe most significant lesson we took away was that no matter how extensively you test your equipment in the lab, field conditions will inevitably present new issues. Paradoxically, these challenges are opportunities to enhance the robustness of your equipment. Hence, this field trip was indispensable, as it exposed problems we would not have encountered in a controlled environment. We are elated to have embarked on this journey and eager to return.\nData Analysis and the Road Ahead # Currently, we are just starting analyzing the data we gathered during this expedition. Our exploration is just beginning, and we are thrilled about the potential discoveries that await us. We will keep you updated on our progress. In the meantime, here are some preliminary findings:\nThe first figure displays the pulse waveform of one of the Gymnorhamphichthys we recorded. The top panel shows the electric organ discharge recording, while the bottom panel illustrates the waveform of the pulses.\nThe second figure showcases a recording from one of our loggers, revealing at least four individuals, with three in the lower frequency range, potentially Sternopygi. The fourth individual operates in the higher frequency range.\nAcknowledgements # First and foremost, I would like to express my deepest gratitude to Jan Benda for extending the invitation to join him on this remarkable field trip. It was an invaluable opportunity to work with him and learn from his expertise.\nThis field trip would not have been possible without the generous assistance of many individuals. The logistical challenges of such an expedition were more significant than we anticipated, and we are incredibly thankful for the support we received.\nDavid de Santana played a pivotal role in connecting us with Christoph Jaster. Without this connection, we would have remained unaware of the existence of the FLONA do Amapa field station. We are sincerely appreciative of his contribution.\nChristoph Jaster diligently managed the permits and logistics from Macapa to the field station. His assistance was indispensable, particularly when our equipment was lost in transit. Furthermore, his kindness was evident when he drove us to the airport at 1 AM when our departure was imminent.\nOur heartfelt thanks go to Telma, our cook at the field station. Her delicious meals and unwavering kindness were a tremendous relief, sparing us the task of preparing our own food. We are deeply grateful for her support.\nJunior proved to be an exceptional boatsman. Communicating through gestures, a few words, and Google Translate, we not only enjoyed our time with him but also spent a memorable night under the stars in our hammocks along the Araguari River bank. We hope to have the privilege of working with him again in the future.\nGroup picture of the overnighter on the river bank. From left to right: Me, Jan, and Junior. ","date":"7 November 2023","permalink":"/posts/brasil_2023/","section":"Posts","summary":"A small report on a field trip to the Amazonian Rainforest in Amapa, Brazil in 2023","title":"Adventures in the Amazon: Exploring Electric Fish in the Rainforest, Brazil 2023"},{"content":"","date":"7 November 2023","permalink":"/tags/amapa/","section":"Tags","summary":"","title":"amapa"},{"content":"","date":"7 November 2023","permalink":"/tags/brazil/","section":"Tags","summary":"","title":"brazil"},{"content":"","date":"7 November 2023","permalink":"/tags/efish/","section":"Tags","summary":"","title":"efish"},{"content":"","date":"7 November 2023","permalink":"/tags/field-trip/","section":"Tags","summary":"","title":"field trip"},{"content":"","date":"7 November 2023","permalink":"/tags/rainforest/","section":"Tags","summary":"","title":"rainforest"},{"content":"","date":"7 November 2023","permalink":"/tags/research/","section":"Tags","summary":"","title":"research"},{"content":"","date":"7 November 2023","permalink":"/tags/science/","section":"Tags","summary":"","title":"science"},{"content":"In order to collect and evaluate the data required for my research, I participate in the creation of both hardware and software initiatives. Please find below a summary of the current projects I am engaged with.\nSubmersible data loggers to record the activity of electric fish in their natural habitats # A submersible data logger to record the electric organ discharge of weakly electric fish in the field. My primary interest involves documenting the natural behaviors of weakly electric fish using electrode grids. However, developing this system has given rise to several intriguing side projects that I am presently working on.\nAn underwater data logger designed for field deployment to record the electric organ discharge of weakly electric fish. These loggers are capable of recording for extended periods, with housings rated for pressures up to 100 meters depth.\nA submersible data logger suitable for SCUBA divers to capture electric activity at great depths. This device is also equipped with an LED to facilitate synchronization with video recordings. You can find an overview here.\nGridtools: A python package to analyze electrode grid data # In the existing data pipeline, fish frequencies are recorded using the wavetracker, resulting in a rather intricate data structure. To streamline the analysis of the data, I have created a Pydantic data model that enables effortless access to the information. The package also includes functions for analyzing, visualizing, preprocessing, and exporting the data. Additionally, I am currently developing a simulation module capable of simulating an entire electrode grid recording, including moving, mobile fish that communicate with one another.\nChirpdetector: A python package to detect and analyze brief communication signals of weakly electric fish # Chirps are one of the two primary methods of communication utilized by wave-type weakly electric fish. These chirps involve modulations of the electric organ discharge frequency that range from 20 ms to 200 ms, making detection challenging when multiple fish are present within a single recording. The only viable approach is through the utilization of a spectrogram with high temporal resolution. The chirpdetector addresses this challenge by employing a faster-RCNN, a object detection algorithm for images, to detect chirps within spectrograms. This enables the quantitative analysis of communication behavior among freely behaving fish in their natural environment, which is the primary objective of my master\u0026rsquo;s thesis.\n","date":"6 November 2023","permalink":"/development/","section":"Hardware and software development","summary":"In order to collect and evaluate the data required for my research, I participate in the creation of both hardware and software initiatives. Please find below a summary of the current projects I am engaged with.","title":"Hardware and software development"},{"content":"","date":"6 November 2023","permalink":"/tags/data-analysis/","section":"Tags","summary":"","title":"data analysis"},{"content":"","date":"6 November 2023","permalink":"/tags/data-engineering/","section":"Tags","summary":"","title":"data engineering"},{"content":"","date":"6 November 2023","permalink":"/tags/data-science/","section":"Tags","summary":"","title":"data science"},{"content":"","date":"6 November 2023","permalink":"/tags/data-science-stack/","section":"Tags","summary":"","title":"data science stack"},{"content":"","date":"6 November 2023","permalink":"/tags/data-visualization/","section":"Tags","summary":"","title":"data visualization"},{"content":"","date":"6 November 2023","permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"machine learning"},{"content":" The Python ecosystem is huge and it is growing every day. It is hard to keep up with all the new libraries and tools. In this post I will share my tech stack for data science in 2023. I will update this post every year to document my plunge into this never ending rabbit hole. # Disclaimer: Everything below is my opinion. If I get something wrong, please let me know. I don\u0026rsquo;t use all of these tools in every project and I don\u0026rsquo;t list all tools that I use here. I am merely providing a list of tools that I particularly enjoy using and that I think are worth checking out as I am writing this post.\nWhy Python? # Pythion is a general purpose programming language that is used for a wide variety of applications. It is a great language for data science because it is easy to learn, has a huge ecosystem of libraries and tools and it is free and open source. And beyond data science, it can be used for almost anything else.\nTerminal and shell # The terminal is where I spend half of my working day. Ideally, it should be fast, functional and pretty. And most importantly, it should be simple. For this reason, I switched from Alacritty to Kitty:\nKitty - Kitty is a fast, featureful, GPU based terminal emulator. It is fast, has great support for unicode and is highly customizable. It is my go to terminal emulator. It is also cross platform and works on Windows, Linux and macOS. Compared to Alacritty, it requires a minimal amount of configuration and is easy to set up. It comes with sane keybindings out of the box and even has build-in support for ligatures, emojis, images and even tiling! No need to configure tmux. The same goes for the shell:\nZsh - As opposed to Bash, Zsh is a shell designed for interactive use. It is a great shell with a huge ecosystem of plugins and themes. I use it with starship as a prompt and vim keybindings. This way I always now where I am, which environment I am in and what git branch I am on. Text editor # The text editor is where I spend the other half of my working day. After trying a lot of different editors, I have settled on two editors that I use for different purposes:\nVisual Studio Code - Visual Studio Code is a free code editor made by Microsoft for Windows, Linux and macOS. It is a bit slow but a breeze to set up and configure and settings sync between devices. It has a huge ecosystem of extensions and is my go to editor for almost everything. Because it is made by Microsoft, it integrates perfectly with GitHub Copilot, a GPT-4 powered AI that helps to make repetitive tasks easier. It is a great tool for writing code.\nNeovim - Neovim is a fork of Vim aiming to improve user experience and plugins. It is a bit harder to set up and configure but it is blazing fast and has a huge ecosystem of plugins. I use it for quick edits and for editing files on remote servers. I used it exclusively for a while but eventually broke my config during a time when I was too busy to fix it.\nNow that we can write code, we need to set up a virtual environment to run it. In my opinion, virtual environments are a must for any Python project. They allow you to create isolated environments for each project and make sure that the correct versions of your dependencies are installed. This is especially important for data science projects because they often require specific versions of Python and its dependencies. It also prevents your system from getting cluttered with dependencies that you don\u0026rsquo;t need. And since the environment can be frozen and shared with others, it makes your project reproducible.\nManging a Python environment # Let\u0026rsquo;s say your system uses Python 3.9 but the package you want to use requires Python 3.11. This is where pyenv comes in:\nPyenv - Pyenv lets you easily switch between multiple versions of Python, just like Anaconda but without Anaconda! It is a great tool for managing Python versions and virtual environments. For smaller projects, pyenv-virtualenv is a great tool that lets you create virtual environments that are all stored in one place. For larger projects, I prefer pythons build in venv module. If you have used Pythons build-in venv module, you know that it is a bit of a hassle to always source .venv/bin/activate. This is where direnv comes in:\nDirenv - Direnv is an environment switcher for the shell. It knows how to hook into bash, zsh, etc. to load or unload environment variables depending on the current directory. This is a great tool for managing environment variables and secrets. I use it to automatically activate and deactivate virtual environments. Pyenv can do this out of the box but only for pyenv virtual environments. Direnv can do this for any virtual environment. Now that we have an environment, we can start setting up a project.\nManaging a Python project # Version control is integral to any software project. It allows you to keep track of changes to your code and makes it easy to collaborate with others. This is where git and GitHub come in:\nGit - Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. It is the de facto standard for version control and is a must for any software project.\nGithub - GitHub is a code hosting platform for version control and collaboration. It lets you and others work together on projects from anywhere.\nNow that we set up a git repository, we can install a pre-commit hook, that runs every time we push changes to the remote repository:\nPre-commit - Pre-commit is a framework for managing and maintaining pre-commit hooks. Pre-commit hooks are scripts that run before a commit is made. They can be used to check for formatting, linting, security issues, etc. I use it to check for formatting, linting and security issues. It is a great tool for maintaining code quality: If a pre-commit hook fails, the commit is aborted and the error is shown to the developer so that it can be fixed. This keeps remote repositories clean and makes sure that all code is formatted, linted and secure. The next tool is a great addition to pre-commit: Keeping the code clean # Black - Black is the uncompromising Python code formatter. It is a great tool for keeping code clean and consistent. Pylint - Pylint is a tool that checks for errors in Python code, tries to enforce a coding standard. Pytest - The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries. If you build a Python package, the next one is particularly useful:\nPoetry - Poetry is a tool for dependency management and packaging in Python. It allows you to declare the libraries your project depends on and it will manage (install/update) them for you. It is a great tool for managing dependencies and packaging because it locks versions of your depencencies to their exact commit hash. Combined with the correct Python version and virtual environment, this makes your project reproducible, which is a must, particularly for data science projects. Data science libraries # Now that we have set up a project, we can start writing code. The following libraries are the ones that I use most often to analyze data, train machine learning models and visualize results:\nNumpy - NumPy is the fundamental package for scientific computing in Python. It is a great library for working with arrays and matrices. It is the foundation of the scientific Python ecosystem and is used by almost every other library.\nPandas - Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. It is a great library for working with tabular data.\nScipy - SciPy is a Python-based ecosystem of open-source software for mathematics, science, and engineering. It is a great library for scientific computing and includes algorithms for optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing, ODE solvers and many more.\nScikit-learn - Scikit-learn is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN. It is a great library for machine learning.\nPytorch - PyTorch is an open source library for deep learning and GPU accelerated computing. It is pain-free to install compared to TensorFlow and has a great API.\nMatplotlib - Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. It is a great library for data visualization. It provides fine grained control over every aspect of a figure and is highly customizable.\nPydantic - Pydantic is a library for data validation and settings management based on Python type hints. It is a great library for validating data and settings. I use it to create data models for my data science projects.\nRich - Rich is a Python library for rich text and beautiful formatting in the terminal. It is a much nicer way to display logs, data and progress bars compared to e.g. tqdm. It is also the progress bar that pip uses when you install something.\nIf a project gets bigger and other people start using it, the following tools are great for documentation:\nDocumenting and sharing # Jupyter - Jupyter is a free, open-source, interactive web tool known as a computational notebook, which researchers can use to combine software code, computational output, explanatory text and multimedia resources in a single document. Still, I try to avoid coding in Jupyter notebooks as much as possible but it is a great tool for sharing and documenting exploratory data analysis.\nMkdocs - MkDocs is a fast, simple and downright gorgeous static site generator that\u0026rsquo;s geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MkDocs builds completely static HTML sites that you can host on GitHub pages, Amazon S3, or anywhere else you choose.\nPdoc - Like mkdocs, pdoc is a documentation generator for Python modules. Unlike mkdocs, it is specifically designed to be used with docstrings in Python code: pdoc automatically generates documentation from type annotations and docstrings. It is also much faster than mkdocs and is best used for API documentation.\nReporting # LaTeX - LaTeX is a typesetting system that includes features designed for the production of technical and scientific documentation. It is my favourite tool for writing reports, posters and presentations. It is a bit hard to learn but once you get the hang of it, it is a breeze to use. And the best part is that it is all in plain text so it works great with version control. Conclusion # As this is the first version of this post, It does include some tools that are obvious choices for data science in python. But I still think they are worth mentioning because they are so foundational. As I update this post every year, I will remove tools that are no longer relevant and add new tools that I think are worth checking out. If you have any suggestions, please let me know.\n","date":"6 November 2023","permalink":"/posts/datascience-stack/","section":"Posts","summary":"A collection of libaries and tools that I use to analyze data with Python","title":"My tech stack for data science with Python in 2023"},{"content":"","date":"6 November 2023","permalink":"/tags/python/","section":"Tags","summary":"","title":"python"},{"content":"","date":"1 May 2023","permalink":"/tags/arduino/","section":"Tags","summary":"","title":"arduino"},{"content":"","date":"1 May 2023","permalink":"/tags/hardware/","section":"Tags","summary":"","title":"hardware"},{"content":"","date":"1 May 2023","permalink":"/tags/linux/","section":"Tags","summary":"","title":"linux"},{"content":"If you\u0026rsquo;ve worked with Arduinos before, you know that beeing constrained to the Arduino IDE can be quite limiting. PlatformIO is a cross-platform, cross-architecture, and multiple framework tool that can help with this. It is designed to make hardware development more comfortable and more efficient.\nPlatformIO is typically advertised as a VSCode plugin, which turns VSCode into an Arduino IDE-like platform. However, there is a lesser-known feature that developers can take advantage of - the simple command-line toolbox. In this blog post, we will walk you through how to install and use PlatformIO via the command line.\nTo begin, PlatformIO is a Python package, so it can be installed from PyPI, including within a virtual environment. However, it is highly recommended to use PlatformIO\u0026rsquo;s installation script instead. Here\u0026rsquo;s how you can install PlatformIO using the installation script:\ncurl -fsSL https://raw.githubusercontent.com/platformio/platformio-core-installer/master/get-platformio.py -o get-platformio.py python3 get-platformio.py During installation, PlatformIO creates its virtual environment, which is beneficial since it doesn\u0026rsquo;t interfere with system packages. However, the standard shell doesn\u0026rsquo;t recognize the PlatformIO executables, so we need to create symbolic links. You can do that using the following commands:\nln -s ~/.platformio/penv/bin/platformio ~/.local/bin/platformio ln -s ~/.platformio/penv/bin/pio ~/.local/bin/pio ln -s ~/.platformio/penv/bin/piodebuggdb ~/.local/bin/piodebuggdb On a Linux system, you also need to add udev rules. This snippet downloads the rules, places them in the appropriate location, reloads the udev service, and adds the current user to the relevant groups:\ncurl -fsSL https://raw.githubusercontent.com/platformio/platformio-core/develop/platformio/assets/system/99-platformio-udev.rules | sudo tee /etc/udev/rules.d/99-platformio-udev.rules To restart udev on debian-based distributions, run:\nsudo service udev restart sudo usermod -a -G dialout $USER sudo usermod -a -G plugdev $USER On arch-based distributions, use the following instead:\nsudo udevadm control --reload-rules sudo udevadm trigger sudo usermod -a -G uucp $USER sudo usermod -a -G lock $USER Log out and log back in for the changes to take effect.\nBy default, PlatformIO enables telemetry. However, you can disable it by running:\npio settings set enable_telemetry No pio settings get Next, you can initialize pio in your directory by creating an example project directory, for example, mkdir pio_test \u0026amp;\u0026amp; cd pio_test. Then, list all the available boards (platforms) by running pio boards. Choose your board and run:\npio project init --ide vim --board teensy41 Now you can edit the source code using your editor of choice. To test if the code compiles, you can simply run:\npio run To flash an attached board, add the following:\npio run --target upload For convenience, I personally created shell aliases comp for compilation and flash to upload. If you let your device access the serial port to print some debug information, you can monitor this by running:\npio device In conclusion, PlatformIO is a powerful tool for hardware development that provides a flexible and efficient workflow for software developers working with hardware. With its support for multiple platforms, frameworks, and libraries, along with a command-line interface and integrated debugging, PlatformIO is an excellent choice for anyone looking to streamline their hardware development workflow.\nPhoto by Vishnu Mohanan on Unsplash\n","date":"1 May 2023","permalink":"/posts/platformio-introduction/","section":"Posts","summary":"An introduction to PlatformIO, a tool that makes software development for microcontrollers easier.","title":"PlatformIO - Lazy hardware development from the command line."},{"content":" Photo courtesy of Lena Wesenberg Welcome to my personal and academic website! I\u0026rsquo;m really glad you\u0026rsquo;re here, and I\u0026rsquo;m excited to share a bit about myself with you. Allow me to introduce myself: I\u0026rsquo;m Patrick, a master\u0026rsquo;s student from Germany with a strong passion for animal behavior and data analysis.\nOn the personal side, I just love making things — whether it\u0026rsquo;s software, hardware, photos, or whatever sparks my interest. It all began back in my high school art classes with drawing, painting, and sculpting. Over time, this creative spark evolved into the digital realm through photography and videography. During my studies, I then discovered my enthusiasm for software development and data science and, working on my thesis, even hardware projects. These days, most of my creative energy finds expression through coding. Additionally, I am strongly drawn to the outdoors. I enjoy going on multi-day hiking trips, and I\u0026rsquo;m really motivated to further my education as a diver — a skill that I\u0026rsquo;m sure will come in handy for my future research.\nShifting to my academic journey, I\u0026rsquo;ve invested a good chunk of time in studying biology, especially animal behavior. Right now, I\u0026rsquo;m pursuing two master\u0026rsquo;s degrees — one in Evolution and Ecology and another in Neurobiology at the University of Tuebingen. The plan is to combine my foundation in evolutionary biology with advanced data analysis skills from the field of neurobiology. What really excites me is where these two fields intersect — animal behavior. My ultimate aim is to contribute meaningfully to the dynamic world of behavioral biology by understanding how weakly electric fish communicate and interact socially. If you\u0026rsquo;re interested in learning more about my studies and research, check out my projects page or take a look at my resume.\nThanks a lot for visiting! Feel free to get in touch through your preferred way of communication.\nWarm regards,\nPatrick\n","date":"25 February 2023","permalink":"/about/","section":"About me","summary":"Photo courtesy of Lena Wesenberg Welcome to my personal and academic website! I\u0026rsquo;m really glad you\u0026rsquo;re here, and I\u0026rsquo;m excited to share a bit about myself with you. Allow me to introduce myself: I\u0026rsquo;m Patrick, a master\u0026rsquo;s student from Germany with a strong passion for animal behavior and data analysis.","title":"About me"},{"content":"This is a small collection of university and research projects I particularly enjoyed working on. I hope you find them interesting!\nDetecting communication signals of weakly electric fish # Understanding the significance of specific communication cues necessitates our ability to detect them, particularly with transient frequency modulation signals like chirps produced by an electric organ discharge in fish. Previous research has mainly focused on immobilizing or artificially stimulating fish or physically separating them, conditions unfavorable for natural communication.\nTo address this challenge, I designed a convolutional neural network-based detector capable of detecting chirps in freely behaving fish. Despite initially training the model on simulated data, it surprisingly performed well on real-world recordings after some fine-tuning. Using this version, I successfully detected approximately 50,000 chirps, marking the largest dataset at that time.\nThe following image illustrates a short segment of a recording featuring two fish. Chirps are visible as frequency fluctuations from the baseline of one of the two fish on a spectrogram. The dots indicate where the detector identified a chirp.\nA spectrogram of a recording of two fish. The dots indicate where the detector detected a chirp. Performing preliminary analyses utilizing this detector, we discovered that chirps could potentially be utilized by the losing fish to indicate submission during competition for a shelter among two fish. I am currently working on refining the resulting dataset through manual annotation and correction to train a deep neural network-based detector, specifically designed for detection tasks and optimized to enhance performance on intricate recordings.\nweygoldt/cnn-chirpdetector A first try of detecting the transient communication signals of weakly electric fish on a spectrogram using a convolutional neural network. Python 0 0 Singing in the dark: Synchronous frequency modulations of weakly electric fish # While analyzing a two-week continuous recording of electric fish in their natural habitat, I observed synchronous frequency modulations on a scale of seconds to two ten minutes between two fish. To detect these modulations, I developed a covariance-based detector, which I then used to analyze the recordings. The following plot shows some examples of detected modulations: Synchronous rises of the EODf betweeen two individuals recorded in freely interacting fish in their natural habitat. By analyzing the estimated positions of fish over time, I demonstrated that those involved in these interactions approach one another following the initiation of their \u0026ldquo;choir.\u0026rdquo; I also created videos depicting some of these diadic interactions, showing the fish moving as data points on an electrode grid and their frequencies changing on the right-hand side.\nThe resulting output from this effort was displayed as a poster at the 2022 International Conference of Neuroethology (ICN). This poster can be accessed through the link provided in the GitHub repository below.\nweygoldt/synchronous-modulations Working directory including scripts for the analysis of synchronised EOD frequency modulations in freely interacting Brown Ghost Knifefish recorded in Colombia. Jupyter Notebook 0 0 Colorblind direction cells in the zebrafish optic tectum # Experimental research has shown that zebrafish are less likely to perceive motion when the only moving element is color. Instead, it is the differences in brightness between moving stimuli that trigger a response (Orger and Baier, 2005). As part of a lab rotation project, we investigated how this behavior manifests in the optic tectum, the primary visual processing center in fish.\nTo achieve this, we employed two-photon calcium imaging to record the activity of direction selective neurons in the optic tectum of zebrafish larvae. Additionally, we simultaneously measured the optokinetic response, a behavioral indicator of motion perception.\nThe ensuing graphs illustrate a comparable pattern between the calcium activities (neural signal) and eye velocities (behavioral output) for the same stimulation conditions. Calcium acitivty in the Zebrafish optic tectum when stimulated with different levels of chromatic and achromatic contrasts. Behavioral output measured in the eye velocities during the optokinetic response shows a similar pattern compared to the neural activity. Our analysis suggested that the direction selective neurons in the optic tectum are likely colorblind, as they primarily respond to variations in brightness rather than color distinctions. As a result of this experiment, we have produced not only a poster but also a more comprehensive report, both of which can be found in the github repository provided below.\nweygoldt/colorblind-directioncells A lab rotation with the systems neuroscience lab, University of Tuebingen, where we tested whether color contrast contributed to encoding motion in direction selective cells of the zebrafish optic tectum. Jupyter Notebook 0 0 ","date":"25 February 2023","permalink":"/work/","section":"Projects","summary":"This is a small collection of university and research projects I particularly enjoyed working on. I hope you find them interesting!\nDetecting communication signals of weakly electric fish # Understanding the significance of specific communication cues necessitates our ability to detect them, particularly with transient frequency modulation signals like chirps produced by an electric organ discharge in fish.","title":"Projects"},{"content":"This is a small selection of projects and activities that I currently pursue in my free time. I hope you find them interesting!\nLinux and open source software # I am a huge fan of Linux and open source software. I got into Linux when I started working in the Neuroethology lab at the University of Tuebingen, where everybody was using it. The idea of a free and open operating system that is not only highly customizable but also very secure instantly fascinated me. Linux has been my main operating system for approximately 2 years now. I am currently running Arch Linux with the Hyprland window manager on both my personal laptop and work PC. I keep a dotfiles repository on GitHub where I store my configuration files and scripts.\nweygoldt/dotfiles The configuration files for my arch linux workstation. Shell 1 0 Scuba diving # I am a certified PADI Advanced Open Water Diver. Diving always fascinated me but doing my Bachelors thesis in a marine biology lab provided the spark to finally get certified. At this time I have been diving in Germany, Indonesia and the Mediterranean Sea. I am really excited to continue my education as a diver, a skill that I\u0026rsquo;m sure will come in handy for my future research. I am particulary drawn towards the idea of becoming a technical- and cave diver to be able to explore challenging environments. In 2023, I got a first chance to combine this skill with my work during a four-week stay at the STARESO marine research station where I assisted PhD-students during sample collection dives.\nScorpion-fish catching in the Mediterranean sea. Photo courtesy of Lena Wesenberg To plan and log my dives, I use Subsurface, an open source dive log software written by no other than the creator of the Linux kernel, Linus Torvalds.\nHiking, photography and everything outdoors # Before I started my studies I spent my weekends with photography trips, mostly hiking in the mountains. Nowadays, I don\u0026rsquo;t have as much time for photography as I used to, but I still enjoy hiking, even if I rarely take my camera. The image below is one of my favorite pictures from that time, a self-portrait taken on a bivouac in the Alps.\nA self-portrait taken on a bivouac in the alps close to the Grimsel pass in Switzerland. For more images, check out my Instagram account or my Youtube channel for some videos of my trips.\n","date":"25 February 2023","permalink":"/play/","section":"What I do for fun","summary":"This is a small selection of projects and activities that I currently pursue in my free time. I hope you find them interesting!\nLinux and open source software # I am a huge fan of Linux and open source software.","title":"What I do for fun"},{"content":"I use this mostly to share technical documentations to things that I think might be useful to others as well. If you have suggestions or comments, feel free to email me!\n","date":"13 June 2022","permalink":"/posts/","section":"Posts","summary":"I use this mostly to share technical documentations to things that I think might be useful to others as well. If you have suggestions or comments, feel free to email me!","title":"Posts"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]